{
  "presentations": [

    {
      "time": "1:00 PM - 1:15 PM",
      "projectId": "csse-3-100",
      "title": "Chewy",
      "studentName": "Ayleen Piteo-Tarpy",
      "studentMajor": "CSSE",
      "projectType": "Internship or Job Opportunity",
      "facultyAdvisor": "Dr. Yusuf Pisan",
      "section": 3,
      "poster": "./posters/csse/ayleen_piteo_poster.png",
      "abstract": "From June to December of 2024 I worked as a software engineer co-op at Chewy. I was responsible for developing and maintaining a backend service that provided accessibility between Chewy’s databases and client-facing teams.\n\nMy first project involved creating a unique identifier for vet clinics to indicate whether they were owned by Chewy. While the implementation was straightforward, I spent significant time learning full-scale development, navigating a large codebase, and learning new development tools like Jenkins and Datadog. Though the project took longer than expected, I gained valuable technical and professional skills, along with strong relationships with my coworkers and mentors, giving me confidence in my ability to take on the next assignment.\n\nThe next project I had was on a sub-service of our main product, and involved sending requests to an API owned by FedEx to validate an address, suggest a new address if needed to comply with postal standards, and return the address back to our endpoint. The service was simple, my assignment was not. The FedEx API we used and the requests we sent them followed SOAP standards, an old API protocol that has been phased out of most modern services. FedEx was updating their APIs to REST, the new standard, and all the SOAP endpoints would be decommissioned at the end of the year. I started this project at the end of October, giving me just over a month to rewrite this entire service with a new API contract, new data validation, new request mapping, and new tests. During that month I gained expertise on unit testing, APIs, SOAP and REST, large-scale debugging, and the full software development life cycle as I recreated a legacy service. I launched successfully in the last week of my co-op, with an error rate under 0.1% and no new errors from my changes.\n\nI’ll be returning to Chewy as a Level 1 Software Engineer in July, and the skills I gained during my co-op have prepared me for a strong start in the industry. My experience improved my research, debugging, and testing abilities, which I’ve applied to my final year at UW in both theory and practical coursework. This internship provided valuable hands-on experience and problem-solving skills, setting the foundation for my software engineering career."
    },
    {
      "time": "1:15 PM - 1:30 PM",
      "projectId": "csse-3-115",
      "title": "Lezza Foods",
      "studentName": "Zeynep Karatas",
      "studentMajor": "CSSE",
      "projectType": "Internship or Job Opportunity",
      "facultyAdvisor": "Dr. Kelvin Sung",
      "section": 3,
      "poster": "./posters/csse/zeynep_karatas_poster.png",
      "abstract": "This capstone project, titled “Financial Data Automation with GPT,” addresses the challenge faced by Lezza Foods—a global wholesale company in the Turkish and Mediterranean cuisine sector—in integrating accounting data from its multiple subsidiaries. The primary objective was to develop an automated data pipeline that retrieves financial information from different accounting software and makes it accessible to ChatGPT. The goal of this integration was to empower the company with a personalized financial assistant capable of generating comparative graphs between subsidiaries and providing strategic insights for future market entry. The project was driven by the need to leverage AI for advanced financial analysis, pattern recognition, and advisory functions, which were previously not possible because of the absence of connectivity between ChatGPT and the company’s internal databases.\n\nThe solution was achieved through a series of iterative approaches. Initial attempts using a cloud data container with a compatible GenAI platform and webhook integration proved either incompatible with the customer’s insistence on using ChatGPT or prohibitively costly due to the large volume of raw accounting data. The final, successful approach involved building a custom API using Python and Flask, deployed on Google Cloud Run, which efficiently transferred data from Google Sheets and desktop accounting software to ChatGPT. This method not only maintained cost-effectiveness but also met the scalability requirements of the project despite limitations on data retrieval imposed by ChatGPT. Ultimately, the project finalized in the successful automation of the financial data pipeline, laying a foundation for further refinement of AI training and integration, and signifying a significant step towards enhanced financial reporting and strategic planning within the company."
    },
    {
      "time": "1:30 PM - 1:45 PM",
      "projectId": "csse-3-130",
      "title": "College Affordability Model: GUI Customization Editor",
      "studentName": "Dong Nguyen",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Kelvin Sung",
      "section": 3,
      "poster": "./posters/csse/dong_nguyen_poster.png",
      "abstract": "While working on the capstone, I had an opportunity to visualize student affordability for our team sponsorship WASAC (Washington Student Achievement Council). Their website requires improvement in user input configuration, which costs a lot of time for their data analyst. To solve this problem, I implemented a feature that allows users to save their input configuration for future visits. \n\nI started my solution with the approach of communication and building a small prototype for my sponsorship for further discussion and final delivery. I have built a detailed plan for every week, on what I am going to implement and report that with a small prototype, I build to my stakeholders so that I can discuss and understand what my stakeholders want or need so that I can quickly merge my work to the real project. I spent my first two weeks analyzing user requirements and proposing my solution. Then in the third week, I started with implementing the backend API to handle user requests to save user input configurations to the database. In the second week, I worked on implementing the first font end to handle user requests sent to the backend. In the third week, I worked on revising the front-end UI of the website, so that users could have a better usage experience. In the following weeks, I worked on revising the UI because the system I had was still too complex for the users to use until the users can self using without my instruction. \n\nFrom this capstone, I have learned how to analyze user stories to have specific functional and non-functional requirements for the system the stakeholder needs. The project was successfully completed and was able to save 10% of their time in analyzing student affordability data"
    },
    {
      "time": "1:45 PM - 2:00 PM",
      "projectId": "csse-3-145",
      "title": "Comparing the Quality of Weather Forecasts",
      "studentName": "JJ Hartog",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Wanda Gregory",
      "section": 3,
      "poster": "./posters/csse/hartogjj_poster.png",
      "abstract": "For my Capstone project I designed and implemented a data analysis and visualization application under the working name ‘Comparing the Quality of Weather Forecasting Services’. This project’s purpose is to generate real time data analytics and visualizations using weather reports and different weather forecasts gathered over recent time. This purpose was chosen due to weather forecasts’ accuracy being highly important to users, but the underlying uncertainty is obscured from the predictions meaning when they are wrong it can be costly and unexpected.\n\nThe backend of this project is developed in Azure to allow for the live recording of weather data throughout the day from specified weather stations using Azure Functions. Forecasts are gathered once daily to quantify the real difference between different forecasts taken at the same time. This data is stored within an Azure SQL Server which allows for easy filtering of the dataset for the user end of the application. This design allows users to view an hourly dataset which ranges from the first time recorded to the most current record last pushed to the SQL Server (which is typically at around 5 am). The datasets are organized based on their type (report or forecast source) and contain categories of information such as temperature, humidity, dew point, wind speed, wind direction, etc. \n\nThe frontend of this project loads the raw datasets locally and then generates derivative datasets which allows users to view how current weather forecasts compare to reports using either the raw datasets or their derivative counterparts. This approach was taken to minimize the cost of the Azure resources while allowing users to view different datasets based on those gathered and stored in Azure since weather forecasts vary quite heavily throughout the year between years.\n\nThis project offers users quantitative measures of how different forecasts compare to each other using real time data analytics and visualizations. This approach of using the live recording of data was utilized due to the impermanence of forecasts and weather report data and the current evolving state of weather forecasting due to the introduction of machine learning forecasting models. This application allows for future extendibility of the datasets through the introduction of new data sources and/or datasets which allows this application to remain relevant in the current landscape when compared to past retrospectives on how weather forecasts performed."
    },
    {
      "time": "2:00 PM - 2:15 PM",
      "projectId": "csse-3-200",
      "title": "Build A PC",
      "studentName": "Sam Kocharov",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Wanda Gregory",
      "section": 3,
      "poster": "./posters/csse/sam_kocharov_poster.jpg",
      "abstract": "What Was Done?\n\nFor my capstone project, I developed a full-stack web application to enhance IT services at Sound PC Repair. A key feature of this application is the Build a PC tool, which allows users to easily select compatible PC components, receive price updates, and order a custom-built PC. This tool includes real-time compatibility checks, modifiable PC templates, dynamic pricing calculations, and an integrated assembly service, providing a seamless experience for both beginners and advanced users.\n\n\nWhy Was It Done?\n\nThrough customer calls and emails, Sound PC Repair frequently receives requests for custom built PCs. However, many users struggled with component compatibility and assembly. While existing solutions like PCPartPicker.com provide part selection assistance, they leave users responsible for assembling the PC themselves. To bridge this gap, I designed this tool to provide an intuitive, guided experience where users can configure a PC tailored to their needs and have it professionally assembled.\n\n\nResults\n\nThe completed web application includes:\n\n- A user-friendly interface that simplifies the PC-building process.\n\n- Real-time compatibility checks to prevent component selection errors.\n\n- Customizable prebuilt PC templates to give users a starting point based on specific use cases such as gaming, workstations, and more.\n\n- Search and filter functionality to help users quickly find PC components based on specifications, brands, and budget.\n\n- Dynamic pricing for budget planning.\n\n- Secure authentication and payment processing using Firebase and Stripe.\n\n- The ability for users to save, load, and modify builds before purchase.\n\n- Integration with Sound PC Repair’s assembly services, allowing users to order a fully assembled PC.\n\n\nSignificance\n\nThis project enhances Sound PC Repair’s online services, allowing users to confidently build and purchase a custom PC without technical expertise. It reduces costly mistakes such as purchasing incompatible PC parts that may not be returnable or require a restocking fee. Also, this web application addresses a key market gap by offering both a configuration tool and an assembly service, which is a feature missing from major competitors like PCPartPicker.com. By providing end to end support from part selection to final assembly, this tool simplifies PC building, purchasing, and service integration in a way that no other platform currently does."
    },
    {
      "time": "2:15 PM - 2:30 PM",
      "projectId": "csse-3-215",
      "title": "Re-Prep: Simplifying Fleet Maintenance On Performance Vehicles",
      "studentName": "Joshua Sommer",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Wanda Gregory",
      "section": 3,
      "poster": "./posters/csse/joshua_sommer_poster.jpg",
      "abstract": "Re-Prep is a web application designed to bring fleet maintenance of performance-built vehicles into the 21st century. By integrating features such as vehicle status monitoring, parts inventory management, custom maintenance intervals, and cost visualization, Re-Prep allows users to keep track of their vehicles in an efficient and user-friendly way. \n\nRe-Prep was designed to be a solution to help users save money and have their fingers on the pulse of their performance fleet. While there are lots of options for fleet management software for taxis, buses, semi-trucks, and other normal fleets, there is no fleet management software that is performance or race focused. Re-Prep solves that problem by providing a highly customizable service that users can tailor to their needs. I am in a unique situation to design Re-Prep as a mechanic at a performance driving school and use my experience and contacts within the industry to design a robust and intuitive system.\n\nBuilt with Python, FastAPI, React, Next.js and MySQL as the main libraries, frameworks, and languages, the system is designed to be scalable, secure, and robust. Key features include digital tracking of maintenance records, analytics of individual vehicles, and individual parts tracking on individual vehicles, and a smart inventory system. Re-Prep aims to enhance user workflow efficiency and improve fleet health, all while saving users money on unnecessary repairs, repeat diagnostic time, and reducing downtime.\n\nSince Re-Prep is an ambitious project as a solo developer, I have great pride in the accomplishments I have achieved over the last six months working on this project. Some of my key accomplishments include integrating the front-end, back-end, and database servers, creating a user authentication system from scratch, and making changes to my service based on my users’ valuable feedback."
    },
    {
      "time": "2:30 PM - 2:45 PM",
      "projectId": "csse-3-230",
      "title": "Off The Books",
      "studentName": "Jonah Brannon",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Wanda Gregory",
      "section": 3,
      "poster": "./posters/csse/jonah_brannon_poster.jpg",
      "abstract": "Off The Books is a cooperative tactical horror FPS built on Unreal Engine 5.  It seeks to fill the gap between casual cooperative horror games and more complex tactical shooters while updating the SWAT simulator formula with several new ideas.  By combining these genres and adding its own unique twists, Off The Books introduces audiences to several features new to either genre.  In each session, up to 6 players will make up a special forces unit and be tasked with navigating procedural generated facilities to contain a dangerous supernatural anomaly.\n\nTo achieve this vision, I developed four distinct systems: A complex level generator for interior environments, a procedural animation system to drive the player character, a combination of Behavior Trees and Goal Oriented Action Planning (GOAP) to power the AI, and a design focused on immersive user interfaces.  Each of these systems was designed around scalability to support rapid content updates for the game’s lifetime.\n\nIn tactical shooters, doorways and passages are the number one threat.  So, my approach to level generation prioritizes placing those thresholds, and dynamically adjusts the contents of each room accordingly.  By using a blend of Behavior Trees and GOAP, my AI can use information from their surroundings, their mental state, and more to decide what action to take.  With procedural animation powering the player character, I’m able to rapidly add new weapons and equipment by blending the precise procedural animation with a small amount of keyframed animation.  Lastly, through a combination of in-world objects, animations, and visual/auditory effects, I can replace traditional FPS user interfaces with an immersive and engaging player experience.\n\nOff The Books is currently in a playable early alpha state, with playtest builds ready for distribution via the Steam platform.  Each of the features described above are working in tandem to deliver a passable gameplay experience representative of the game’s core goals.  The development of Off The Books will continue beyond this capstone to produce a commercial ready product in the next 6-12 months."
    },
    {
      "time": "2:45 PM - 3:00 PM",
      "projectId": "csse-3-245",
      "title": "Heagle - A Management Tool to Simplify Apartment Hunting",
      "studentName": "Ilda Kim",
      "studentMajor": "CSSE",
      "projectType": "Individual project",
      "facultyAdvisor": "Dr. Wanda Gregory",
      "section": 3,
      "poster": "./posters/csse/ilda_kim_poster.png",
      "abstract": "For the Winter 2025 CSSE capstone, I built Heagle, a management tool designed to simplify the apartment hunting process. My main goal was to bring organization, efficiency and automation to allow future apartment hunters to focus more on making decisions rather than gathering data. The idea for this project came from my own frustrations during my last apartment search, where I encountered unnecessary stress due to disorganized, fragmented information online, spending too much time gathering details, and revisiting listing sites multiple times a day for updates. \n\nTo address these challenges, I implemented an organization system based on a Kanban board, allowing users to organize their apartment search with lists where each card represents a home. Users can add a new card (apartment), and the app will automatically retrieve relevant property details, storing and displaying them in a centralized place. Additionally, users can add their own contextual notes or manually re-fetch data as needed.\n\nTo minimize the need for revisiting rental listings for updates, I implemented a subscription system that provides automatic updates on critical and frequently changing details, such as rent price, availability status, and availability date. Users can track rent history through a timestamped log. Instead of a basic list, users can create smart lists, which dynamically group cards based on specified conditions \n\nMy project consists of three core components, each with distinct responsibilities. The main application, Heagle, is built with Vue.js and is responsible for responsive interactions and accurate data flow. The second component, a data aggregator named go-house-spider, is developed in Golang and is powered by chromedp to extract key property details from multiple listing websites. Due to the unpredictability of human-posted rental listings, I adopted a rapid prototyping approach to quickly test methods. Finally, the backend server, built using Golang’s Gin web framework, brings these components together with the database.\n\nI consider this project a success— it led me to discover what I now consider my primary programming language: Go. I plan on further refining go-house-spider. For Heagle’s deployment, I plan on a self-hosted approach, using the file system instead of a database for storage."
    }
  ]
}